{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Digit recognition program using KNN algorithm.\n",
    ">The program reads images as pixel rows where each pixel has an RGB value.\n",
    "\n",
    ">each pixel value is normalized by the thresholding code block.\n",
    "\n",
    ">all normalized pixel values of a row are added and a row value is generated.\n",
    "\n",
    ">so in this way, each image can be described as a 28 featured data point (each image is 28x28px).\n",
    "\n",
    ">these data points are already bifurcated into train and test folder by me.[datapoints.zip]\n",
    "\n",
    ">a dataset is then generated by reading these points, this dataset is of the form {group:[group_points]}\n",
    "\n",
    ">then the KNN algorithm works and we can see the output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('fivethirtyeight')\n",
    "%matplotlib inline\n",
    "import glob\n",
    "import os\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to desaturate the image by turing pixels into black or white based on their value. \n",
    "#lighter pixels are turned white and darker pixels are turned black.\n",
    "def threshold(img_array):\n",
    "    row_avg=[]\n",
    "    for eachrow in img_array:\n",
    "        row_avg.append(np.mean(eachrow))\n",
    "    avg_color=np.mean(row_avg)\n",
    "    #print(avg_color)\n",
    "    \n",
    "    new_image=np.eye(len(img_array))\n",
    "    \n",
    "    for row in range(len(img_array)):\n",
    "        for pixel in range(len(img_array[row])):\n",
    "            if img_array[row][pixel]>=avg_color:\n",
    "                new_image[row][pixel]=255\n",
    "            else:\n",
    "                new_image[row][pixel]=0\n",
    "    new_image=np.array(new_image)\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a slightly different codeblock to threshold, same principle, just for different image format.\n",
    "def threshold2(img_array):\n",
    "    new=np.eye(len(img_array))\n",
    "    rowavg=[]\n",
    "    for eachrow in img_array:\n",
    "        rowavg.append(np.mean(eachrow))\n",
    "    avgcolor=np.mean(rowavg)\n",
    "    for row in range(len(img_array)):\n",
    "        for pixel in range(len(img_array[row])):\n",
    "            if np.mean(img_array[row][pixel])>=avgcolor:\n",
    "                new[row][pixel]=255\n",
    "            else:\n",
    "                new[row][pixel]=0\n",
    "    new=np.array(new)\n",
    "    return new\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to read the entire pixel row of the image and give a value to that row\n",
    "#these values will be then passed to the KNN algorithm\n",
    "def value(row):\n",
    "    sum=0\n",
    "    for i in range(len(row)):\n",
    "        sum+=row[i]/float(i+1)\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#to read the training images and extracting data out of each image\n",
    "#change this path to where your folder is\n",
    "path='C:/Users/hp/datascience/digit_recognition/train_data/'\n",
    "train_file=open('train_file21.csv','a')\n",
    "folders=os.listdir(path)\n",
    "\n",
    "for label in range(1,29):\n",
    "    train_file.write(str(label)+',')\n",
    "train_file.write('label'+'\\n')\n",
    "\n",
    "for folder in folders:\n",
    "    images_in_folder=os.listdir(path+folder)\n",
    "    for image in images_in_folder:\n",
    "        #print(folder,'--------',image)\n",
    "        img=Image.open(path+folder+'/'+image)\n",
    "        image_array=np.array(img)\n",
    "        try:\n",
    "            image_t=threshold(image_array)\n",
    "        except:\n",
    "            image_t=threshold2(image_array)\n",
    "        image_t_list=image_t.tolist()\n",
    "        \n",
    "        for row_data in image_t_list:\n",
    "            linetowrite=str(value(row_data))+','\n",
    "            train_file.write(linetowrite)\n",
    "        train_file.write(folder)\n",
    "        train_file.write('\\n')\n",
    "print('done')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'train_file21.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-5991a2d52355>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#loading the extracted data on the program\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train_file21.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#replacing all missing data with NaN value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'?'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1708\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'train_file21.csv' does not exist"
     ]
    }
   ],
   "source": [
    "#loading the extracted data on the program\n",
    "df=pd.read_csv('train_file21.csv')\n",
    "\n",
    "#replacing all missing data with NaN value\n",
    "df.replace('?',np.nan,inplace=True)\n",
    "\n",
    "#deleting the column with id, 1 in the argument indicates 'column', so this will delete the 'column' containing 'id'\n",
    "#df.drop(['id'],1,inplace=True)\n",
    "df.drop(['1'],1,inplace=True)\n",
    "df.drop(['2'],1,inplace=True)\n",
    "df.drop(['3'],1,inplace=True)\n",
    "df.drop(['4'],1,inplace=True)\n",
    "df.drop(['25'],1,inplace=True)\n",
    "df.drop(['26'],1,inplace=True)\n",
    "df.drop(['27'],1,inplace=True)\n",
    "df.drop(['28'],1,inplace=True)\n",
    "#delete all the rows that have NaN in them\n",
    "dk=df.dropna()\n",
    "full_data=dk.values.tolist()\n",
    "headers = df.dtypes.index\n",
    "header=headers.tolist()\n",
    "header2=header[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "points=[]\n",
    "for column in header:\n",
    "    points.append(df[column].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for point in points:\n",
    "    del point[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to arrange the data into a KNN acceptable format\n",
    "dataset={}\n",
    "for i in range(1,len(df)):\n",
    "    point=[]\n",
    "    label=df.loc[[i]]['label'].tolist()[0]\n",
    "    if label not in dataset:\n",
    "        dataset[label]=[]\n",
    "    for head in header2:\n",
    "        point.append(df.loc[[i]][head].tolist()[0])\n",
    "    dataset[label].append(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to count the apprearence of an element for KNN\n",
    "def class_counts(data):\n",
    "    counts={}\n",
    "    for row in data:\n",
    "        label=row\n",
    "        if label not in counts:\n",
    "            counts[label]=0\n",
    "        counts[label]+=1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_nearest_neighbours(data,predict,k):\n",
    "    dist=[]\n",
    "    rev={}\n",
    "    for group in data:\n",
    "        for features in data[group]:\n",
    "            distance=np.linalg.norm(np.array(features)-np.array(predict))\n",
    "            dist.append([distance,group])\n",
    "    votes=[i[1] for i in sorted(dist)[:k]]\n",
    "    uniqueVotes=class_counts(votes)\n",
    "    \n",
    "    #print('sorted distance: ',sorted(dist))\n",
    "    #print('votes: ',uniqueVotes)\n",
    "    \n",
    "    for vote in uniqueVotes:\n",
    "        rev[uniqueVotes[vote]]=vote\n",
    "    #data[rev[max(rev)]].append(predict)\n",
    "    return rev[max(rev)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print (k_nearest_neighbours(dataset,test,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image='C:/Users/hp/datascience/digit_recognition/img_93.jpg'\n",
    "def predict(image,show=False):\n",
    "    img=Image.open(image)\n",
    "    if show:\n",
    "        print('input image:')\n",
    "        plt.grid(False)\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "    pred=[]\n",
    "    image_array=np.array(img)\n",
    "    try:\n",
    "        image_t=threshold(image_array)\n",
    "    except:\n",
    "        image_t=threshold2(image_array)\n",
    "    image_t_list=image_t.tolist()\n",
    "    for row_data in image_t_list:\n",
    "        pred.append(value(row_data))\n",
    "    pred=pred[4:24]\n",
    "    #pred\n",
    "    answer=k_nearest_neighbours(dataset,pred,21)\n",
    "    #print('predicted value: ',answer)\n",
    "    return answer\n",
    "    #return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path='C:/Users/hp/datascience/digit_recognition/drawn.png'\n",
    "predict(path,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path='C:/Users/hp/datascience/digit_recognition/test/'\n",
    "test_imgs=os.listdir(path)\n",
    "i=np.random.randint(0,len(test_imgs))\n",
    "pic=test_imgs[i]\n",
    "#p=Image.open(path+pic)\n",
    "p=predict(path+pic,True)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='C:/Users/hp/datascience/digit_recognition/test_data/'\n",
    "test_folders=os.listdir(path)\n",
    "#np.random.shuffle(test_folders)\n",
    "count=0\n",
    "true_prediction=0\n",
    "pred_list={int(folder):{int(folder):0 for folder in test_folders} for folder in test_folders}\n",
    "for folder in test_folders:\n",
    "    \n",
    "    img_list=os.listdir(path+folder)\n",
    "    \n",
    "    for image in img_list:\n",
    "        \n",
    "        image_path=path+folder+'/'+image\n",
    "        prediction=str(int(predict(image_path)))\n",
    "        pred_list[int(folder)][int(prediction)]+=1\n",
    "        if prediction==folder:\n",
    "            true_prediction+=1\n",
    "                      \n",
    "        count+=1\n",
    "        \n",
    "            \n",
    "print('test size: ',count)\n",
    "print('true predictions: ',true_prediction)\n",
    "print('confidence: ',true_prediction/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b: blue\n",
    "#g: green\n",
    "#r: red\n",
    "#c: cyan\n",
    "#m: magenta\n",
    "#y: yellow\n",
    "#k: black\n",
    "#w: white\n",
    "color=['b','g','r','c','m','y','k']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(20,10))\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.xlabel('Actual Digit',fontsize=25)\n",
    "plt.ylabel('Predicted Value',fontsize=25)\n",
    "plt.title('Prediction Chart',fontsize=25)\n",
    "major_ticks = np.arange(0, 10, 1)                                              \n",
    "plt.xticks(major_ticks,fontsize=25)                                                       \n",
    "plt.yticks(major_ticks,fontsize=25) \n",
    "plt.grid(True)\n",
    "\n",
    "for num in pred_list:\n",
    "    num_data=pred_list[num]\n",
    "    for pred in num_data:\n",
    "        plt.scatter([num],[pred],color='c',s=pred_list[num][pred]*5.5)\n",
    "        if pred_list[num][pred]>0:\n",
    "            plt.annotate(str(pred_list[num][pred]),xy=(num,pred),fontsize=15, xytext=(10,10), textcoords='offset points')\n",
    "        #plt.text(num,pred,str(pred_list[num][pred]))\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
